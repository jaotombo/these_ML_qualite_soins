{"cells":[{"cell_type":"markdown","id":"f2da5720","metadata":{"id":"f2da5720"},"source":["# First Classification (rework)"]},{"cell_type":"code","execution_count":1,"id":"d979cdfe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21855,"status":"ok","timestamp":1648482905586,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"d979cdfe","outputId":"bf7285d4-dfd9-4b01-fe0a-5449bb5bd5b7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n","  \"\"\")\n"]},{"output_type":"stream","name":"stdout","text":["Collecting catboost\n","  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n","\u001b[K     |████████████████████████████████| 76.1 MB 2.5 MB/s \n","\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (3.10.0.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n","Installing collected packages: catboost\n","Successfully installed catboost-1.0.4\n","Collecting boruta\n","  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.21.5)\n","Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.0.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->boruta) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->boruta) (1.1.0)\n","Installing collected packages: boruta\n","Successfully installed boruta-0.3\n"]}],"source":["# Import libraries\n","import numpy as np\n","import pandas as pd\n","import os\n","import psycopg2\n","import matplotlib.pyplot as plt\n","import random\n","import dill\n","import pickle\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","import lightgbm as lgb\n","try:\n","  from catboost import CatBoostClassifier\n","except:\n","  !pip install catboost\n","  from catboost import CatBoostClassifier\n","\n","try:\n","  # feature selection through BorutaPy\n","  from boruta import BorutaPy\n","except:\n","  !pip install boruta\n","  from boruta import BorutaPy\n","import time\n","from datetime import timedelta\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"id":"594fbd56","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1648482905588,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"594fbd56"},"outputs":[],"source":["# PARAMETERS\n","\n","icu_stays = True # set to TRUE if we want to have only ICU stays\n","med_7 = False # set to false if we want to avoid using Med7 preprocessing\n","\n","if med_7 == False: \n","    tag_med7 = '_nomed7'\n","else:\n","    tag_med7 = ''\n","\n","if icu_stays == True:\n","    tag_icu = '_icu'\n","    icu_folder = 'icu_only'\n","    title_tag = 'Only ICU Hospitalization'\n","else:\n","    tag_icu = ''\n","    icu_folder = 'all_hosp'\n","    title_tag = 'All Hospitalization'"]},{"cell_type":"code","execution_count":3,"id":"A4CzjnyZfiI8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17239,"status":"ok","timestamp":1648482922817,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"A4CzjnyZfiI8","outputId":"14cd8ae4-fd49-4645-b227-df8cdab18057"},"outputs":[{"output_type":"stream","name":"stdout","text":["We're running Colab\n","Colab: mounting Google drive on  /content/gdrive\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive/MIMIC-III Text Mining\n"]}],"source":["try:\n","  from google.colab import drive\n","  IN_COLAB=True\n","except:\n","  IN_COLAB=False\n","\n","if IN_COLAB:\n","  print(\"We're running Colab\")\n","\n","if IN_COLAB:  \n","  # Mount the Google Drive at mount\n","  mount='/content/gdrive'\n","  print(\"Colab: mounting Google drive on \", mount)\n","  # connect your colab with the drive\n","  drive.mount(mount)\n","\n"," # Switch to the directory on the Google Drive that you want to use\n","  import os\n","  path_to_repo = mount + \"/My Drive/MIMIC-III Text Mining\"\n","\n","else:\n","  path_to_repo = os.path.join(os.path.dirname(os.getcwd()))\n","\n","  \n","print(path_to_repo)"]},{"cell_type":"code","execution_count":4,"id":"44f7c4de","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1648482922820,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"44f7c4de","outputId":"d1f6f3dc-68bc-4de6-faa5-c77e3524e800"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/MIMIC-III Text Mining/Readmission/data/icu_only/\n"]}],"source":["path_to_data = os.path.join(path_to_repo,\"Readmission\",\"data\", icu_folder,\"\")\n","print(path_to_data)"]},{"cell_type":"code","execution_count":5,"id":"c3b9468f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1648482922822,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"c3b9468f","outputId":"1a67065d-d58e-4cb9-da46-4a3c4855d98b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/MIMIC-III Text Mining/Readmission/data/icu_only/processed/\n"]}],"source":["path_to_processed = os.path.join(path_to_data,\"processed\",\"\")\n","print(path_to_processed)"]},{"cell_type":"code","execution_count":6,"id":"cf862512","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":610,"status":"ok","timestamp":1648482923415,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"cf862512","outputId":"ac7347b6-4ef3-45b7-8884-385d6eb000a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/MIMIC-III Text Mining/Readmission/data/icu_only/models/\n"]}],"source":["path_to_models = os.path.join(path_to_data,\"models\",\"\")\n","os.makedirs(path_to_models, exist_ok=True) # we create the directory if it does not exist\n","print(path_to_models)"]},{"cell_type":"code","execution_count":7,"id":"qKAuCeUfviXA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":787,"status":"ok","timestamp":1648482924198,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"qKAuCeUfviXA","outputId":"29c7ec4f-a4cd-461b-9e35-814edcef533c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/MIMIC-III Text Mining/Readmission/data/icu_only/models/\n"]}],"source":["path_to_boruta = os.path.join(path_to_models,\"boruta\",\"\")\n","os.makedirs(path_to_boruta, exist_ok=True) # we create the directory if it does not exist\n","print(path_to_models)"]},{"cell_type":"code","execution_count":8,"id":"a169b6c7","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648482924199,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"a169b6c7"},"outputs":[],"source":["# PARAMETERS\n","\n","session_seed = 42 # set seed for our session\n","include_diag = True # set to True if we want to also process the diagnosis column\n","include_test = True # set to True if we want to also process the test set\n","feature_boruta = False # set to True if we want to select features with BorutaPy\n","\n","random.seed(session_seed)\n","\n","if include_diag == True: diag_tag = '_diag'\n","else: diag_tag = ''"]},{"cell_type":"code","execution_count":9,"id":"e6a727ff","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648482924200,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"e6a727ff"},"outputs":[],"source":["def load_datasets(method, include_diag = True, include_test = True):\n","    \"\"\"\n","    Function to load train, test and validation set based on the chosen method\n","    method: string for the processing method we want to load\n","    include_diag: if we want to load the dataframes with the diagnosis text, default True\n","    include_test: if we want to load also the test set, default True\n","    \"\"\"\n","    global path_to_processed\n","    if include_diag == True: diag_tag = '_diag'\n","    else: diag_tag = ''\n","    # load it back\n","    train = pd.read_feather(f'{path_to_processed}train_{method}{diag_tag}{tag_med7}')\n","    val = pd.read_feather(f'{path_to_processed}val_{method}{diag_tag}{tag_med7}')\n","    if include_test == True:\n","        test = pd.read_feather(f'{path_to_processed}test_{method}{diag_tag}{tag_med7}')\n","    else: test = []\n","    return train, val, test"]},{"cell_type":"code","execution_count":10,"id":"311d9ea3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1001,"status":"ok","timestamp":1648482925196,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"311d9ea3","outputId":"c4bf59cf-fd4a-41e2-afb3-bd1f5e013c7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train composition:\n","target\n","0         22746\n","1          1236\n","dtype: int64\n","\n","Val composition:\n","target\n","0         2528\n","1          137\n","dtype: int64\n","\n","Test composition:\n","target\n","0         6319\n","1          343\n","dtype: int64\n"]}],"source":["y_train = pd.read_feather(f'{path_to_processed}y_train{tag_med7}')\n","y_val = pd.read_feather(f'{path_to_processed}y_val{tag_med7}')\n","if include_test == True:\n","    y_test = pd.read_feather(f'{path_to_processed}y_test{tag_med7}')\n","print('Train composition:')  \n","print(y_train.value_counts())\n","print('\\nVal composition:')  \n","print(y_val.value_counts())\n","if include_test == True:\n","    print('\\nTest composition:')  \n","    print(y_test.value_counts())"]},{"cell_type":"code","execution_count":11,"id":"f8e41676","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1648482925198,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"f8e41676"},"outputs":[],"source":["# initialize a dictionary for the results of all the models\n","train_roc = {}\n","val_roc = {}\n","test_roc = {}\n","\n","# For Boruta\n","train_roc_boruta = {}\n","val_roc_boruta = {}\n","test_roc_boruta = {}"]},{"cell_type":"code","execution_count":12,"id":"8c8b4074","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1648482925198,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"8c8b4074"},"outputs":[],"source":["model_dict = {\n","    'log_reg': LogisticRegression(solver = \"saga\", penalty = 'l1', random_state = session_seed, n_jobs = -1) # default penalty is l2, we do lasso\n","    , 'dec_tree': DecisionTreeClassifier(random_state = session_seed)\n","    #, 'bag_tree': BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 10, random_state = session_seed, n_jobs = -1)\n","    , 'rand_for': RandomForestClassifier(random_state = session_seed, n_jobs = -1)\n","    , 'gboost': GradientBoostingClassifier(random_state = session_seed)\n","    , 'lightgbm': lgb.LGBMClassifier(random_state = 42, n_jobs = -1, deterministic = True)\n","    , 'catboost': CatBoostClassifier(random_seed = 42)\n","}"]},{"cell_type":"code","execution_count":13,"id":"fff1826a","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1648482925199,"user":{"displayName":"Luca Adorni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggt-jhhB0G329szPu-ul9xR7_wbTqibbe3M-vnKJQ=s64","userId":"07135966571450304185"},"user_tz":-120},"id":"fff1826a"},"outputs":[],"source":["method_list = ['frequency', 'one_hot','tf_idf', 'word2vec', 'GloVe', 'W2V_Med', 'Bio_W2V']"]},{"cell_type":"code","execution_count":null,"id":"1b8fc8b9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b8fc8b9","outputId":"a9fb93ee-406b-427b-acdf-a10382fdbbde","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["log_reg\n","frequency\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n","https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n","  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"]},{"output_type":"stream","name":"stdout","text":["Model already trained\n","0:00:00.262445\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n","  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n","/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n","  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"]},{"output_type":"stream","name":"stdout","text":["one_hot\n"]}],"source":["for model_name, model in model_dict.items(): \n","    print(model_name)\n","    # initialize lists with the results\n","    results_train = []\n","    results_val = []\n","    results_test = []\n","    results_train_boruta = []\n","    results_val_boruta = []\n","    results_test_boruta = []\n","    for method in method_list:\n","        print(method)\n","        train, val, test = load_datasets(method, include_diag = include_diag, include_test = include_test) # we load the dataset we want to use\n","        start_time = time.monotonic()\n","        try:\n","            with open(f'{path_to_models}_{model_name}_{method}{diag_tag}{tag_med7}', 'rb') as file:\n","                model = dill.load(file)\n","            print('Model already trained')\n","            trained = True\n","        except:\n","            trained = False\n","            model.fit(train, y_train) # we fit our model\n","            print('Model successfully trained')\n","        end_time = time.monotonic()\n","        print(timedelta(seconds=end_time - start_time))\n","        results_train.append(roc_auc_score(y_train.target, model.predict_proba(train)[:, 1])) # append the ROC score\n","        results_val.append(roc_auc_score(y_val.target, model.predict_proba(val)[:, 1]))\n","        if include_test == True:\n","            results_test.append(roc_auc_score(y_test.target, model.predict_proba(test)[:, 1]))\n","        if trained == False:\n","          with open(f'{path_to_models}_{model_name}_{method}{diag_tag}{tag_med7}', 'wb') as file: # and save the fitted model\n","            dill.dump(model, file)\n","            print('Model saved')\n","        # BORUTA -----------------------------------------------------------------------------------------\n","        if feature_boruta == True and model_name != 'log_reg' and model_name != 'dec_tree':\n","          start_time = time.monotonic()\n","          try:\n","            with open(f'{path_to_boruta}_{model_name}_{method}{diag_tag}{tag_med7}_feat_selector', 'rb') as file:\n","                feat_selector = dill.load(file)\n","            print('Boruta Model already trained')\n","          except:\n","            feat_selector = BorutaPy(model, random_state = session_seed)\n","            # find all relevant features - 5 features should be selected\n","            feat_selector.fit(np.array(train), np.array(y_train))\n","            print('Boruta Model trained')\n","            with open(f'{path_to_boruta}_{model_name}_{method}{diag_tag}{tag_med7}_feat_selector', 'wb') as file: # and save the fitted model\n","              dill.dump(feat_selector, file)\n","              print('Model saved')\n","          # call transform() on X to filter it down to selected features\n","          train_filtered = feat_selector.transform(np.array(train))\n","          print('Number of features selected: {}'.format(train_filtered.shape[1]))\n","          val_filtered = feat_selector.transform(np.array(val))\n","          if include_test == True:\n","            test_filtered = feat_selector.transform(np.array(test))\n","          end_time = time.monotonic()\n","          print(timedelta(seconds=end_time - start_time))\n","          # FIT MODEL WITH FEATURE SELECTION -------------------------\n","          start_time = time.monotonic()\n","          try:\n","              with open(f'{path_to_boruta}_{model_name}_{method}{diag_tag}{tag_med7}_boruta', 'rb') as file:\n","                  model = dill.load(file)\n","              print('Reduced Model already trained')\n","              trained = True\n","          except:\n","              trained = False\n","              model.fit(train, y_train) # we fit our model\n","              print('Reduced Model successfully trained')\n","          end_time = time.monotonic()\n","          print(timedelta(seconds=end_time - start_time))\n","          results_train_boruta.append(roc_auc_score(y_train.target, model.predict_proba(train)[:, 1])) # append the ROC score\n","          results_val_boruta.append(roc_auc_score(y_val.target, model.predict_proba(val)[:, 1]))\n","          if include_test == True:\n","              results_test_boruta.append(roc_auc_score(y_test.target, model.predict_proba(test)[:, 1]))\n","          if trained == False:\n","            with open(f'{path_to_boruta}_{model_name}_{method}{diag_tag}{tag_med7}_boruta', 'wb') as file: # and save the fitted model\n","              dill.dump(model, file)\n","              print('Model saved')\n","    train_roc[model_name] = results_train # finally we add the result lists to our dictionary\n","    val_roc[model_name] = results_val\n","    test_roc[model_name] = results_test\n","    if feature_boruta == True:\n","      train_roc_boruta[model_name] = results_train_boruta\n","      val_roc_boruta[model_name] = results_val_boruta\n","      test_roc_boruta[model_name] = results_test_boruta"]},{"cell_type":"code","execution_count":null,"id":"d304971d","metadata":{"id":"d304971d"},"outputs":[],"source":["# Then we save all our results\n","with open(f'{path_to_models}train_results{diag_tag}{tag_med7}.pkl', 'wb') as file:\n","    pickle.dump(train_roc, file)\n","with open(f'{path_to_models}val_results{diag_tag}{tag_med7}.pkl', 'wb') as file:\n","    pickle.dump(val_roc, file)\n","if include_test == True:\n","    with open(f'{path_to_models}test_results{diag_tag}{tag_med7}.pkl', 'wb') as file:\n","        pickle.dump(test_roc, file)"]},{"cell_type":"code","execution_count":null,"id":"mR60CBZNduwp","metadata":{"id":"mR60CBZNduwp"},"outputs":[],"source":["def get_final_res_list(dict):\n","  \"\"\"\n","  Function to transform our results to a list of list usable by the tabulate function\n","  \"\"\"\n","  results = []\n","  for key, values in dict.items():\n","    new_res = [[key], values]\n","    flat_list = [item for sublist in new_res for item in sublist]\n","    results.append(flat_list)\n","  return results"]},{"cell_type":"code","execution_count":null,"id":"lC5wpM4pdR7O","metadata":{"id":"lC5wpM4pdR7O"},"outputs":[],"source":["from tabulate import tabulate\n","train_results = get_final_res_list(train_roc)\n","print(tabulate(train_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]},{"cell_type":"code","execution_count":null,"id":"vNpS2BdheCIr","metadata":{"id":"vNpS2BdheCIr"},"outputs":[],"source":["val_results = get_final_res_list(val_roc)\n","print(tabulate(val_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]},{"cell_type":"code","execution_count":null,"id":"WohabOxWhYoz","metadata":{"id":"WohabOxWhYoz"},"outputs":[],"source":["if include_test == True:\n","    test_results = get_final_res_list(test_roc)\n","    print(tabulate(test_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]},{"cell_type":"markdown","id":"756564da","metadata":{"id":"756564da"},"source":["# Results"]},{"cell_type":"code","execution_count":null,"id":"763d2f28","metadata":{"id":"763d2f28"},"outputs":[],"source":["# Then we save all our results\n","with open(f'{path_to_models}train_results{diag_tag}{tag_med7}.pkl', 'rb') as file:\n","    train_roc = pickle.load(file)\n","with open(f'{path_to_models}val_results{diag_tag}{tag_med7}.pkl', 'rb') as file:\n","    val_roc = pickle.load(file)\n","if include_test == True:\n","    with open(f'{path_to_models}test_results{diag_tag}{tag_med7}.pkl', 'rb') as file:\n","        test_roc = pickle.load(file)"]},{"cell_type":"code","execution_count":null,"id":"87f6b515","metadata":{"id":"87f6b515"},"outputs":[],"source":["train_results = get_final_res_list(train_roc)\n","print(title_tag)\n","print(tabulate(train_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]},{"cell_type":"code","execution_count":null,"id":"a227e52a","metadata":{"id":"a227e52a"},"outputs":[],"source":["val_results = get_final_res_list(val_roc)\n","print(title_tag)\n","print(tabulate(val_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]},{"cell_type":"code","execution_count":null,"id":"5fecfb8b","metadata":{"id":"5fecfb8b"},"outputs":[],"source":["if include_test == True:\n","    test_results = get_final_res_list(test_roc)\n","    print(title_tag)\n","    print(tabulate(test_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]},{"cell_type":"code","execution_count":null,"id":"73fd2767","metadata":{"id":"73fd2767","outputId":"0e940369-b1cf-4ed1-9ecd-cefc827a7a34"},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\luca9\\Documents\\MIMIC-III Text Mining\\Readmission\\data\\all_hosp\\models\\\n"]}],"source":["if icu_stays == True:\n","    other_folder = 'all_hosp'\n","    title_tag = 'All Hospitalization'\n","else:\n","    title_tag = 'Only ICU Hospitalization'\n","    other_folder = 'icu_only'\n","\n","path_to_other = os.path.join(path_to_repo,\"Readmission\",\"data\", other_folder, \"models\",\"\")\n","print(path_to_other)"]},{"cell_type":"code","execution_count":null,"id":"9949247a","metadata":{"id":"9949247a","outputId":"3dcbacc6-da4d-4a48-a85c-a4ac34fc8bcc"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'C:\\\\Users\\\\luca9\\\\Documents\\\\MIMIC-III Text Mining\\\\Readmission\\\\data\\\\all_hosp\\\\models\\\\train_results_nomed7.pkl'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11740/1540856178.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Then we save all our results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{path_to_other}train_results{diag_tag}{tag_med7}.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_roc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{path_to_other}val_results{diag_tag}{tag_med7}.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mval_roc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\luca9\\\\Documents\\\\MIMIC-III Text Mining\\\\Readmission\\\\data\\\\all_hosp\\\\models\\\\train_results_nomed7.pkl'"]}],"source":["# Then we save all our results\n","with open(f'{path_to_other}train_results{diag_tag}{tag_med7}.pkl', 'rb') as file:\n","    train_roc = pickle.load(file)\n","with open(f'{path_to_other}val_results{diag_tag}{tag_med7}.pkl', 'rb') as file:\n","    val_roc = pickle.load(file)\n","if include_test == True:\n","    with open(f'{path_to_other}test_results{diag_tag}{tag_med7}.pkl', 'rb') as file:\n","        test_roc = pickle.load(file)"]},{"cell_type":"code","execution_count":null,"id":"33e6b136","metadata":{"id":"33e6b136"},"outputs":[],"source":["train_results = get_final_res_list(train_roc)\n","print(title_tag)\n","print(tabulate(train_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]},{"cell_type":"code","execution_count":null,"id":"e5fac8c0","metadata":{"id":"e5fac8c0"},"outputs":[],"source":["val_results = get_final_res_list(val_roc)\n","print(title_tag)\n","print(tabulate(val_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]},{"cell_type":"code","execution_count":null,"id":"0262e584","metadata":{"id":"0262e584"},"outputs":[],"source":["if include_test == True:\n","    test_results = get_final_res_list(test_roc)\n","    print(title_tag)\n","    print(tabulate(test_results, headers = ['Frequency','One Hot', 'TF-IDF', 'Word2Vec', 'GloVe', 'W2V_Med', 'Bio_W2V']))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"[COLAB] 5. First Classification (rework).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}